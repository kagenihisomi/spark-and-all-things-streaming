{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.remote(\"sc://localhost:15002\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that Spark Connect is setup correctly\n",
    "Executing a hello world of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 01:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 01:00:00|\n",
      "|  4|5.0|string3|2000-03-01|2000-01-03 01:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date\n",
    "from pyspark.sql import Row\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello world - QuestDB Connect\n",
    "From the [QuestDB Spark Connector](https://questdb.io/docs/third-party-tools/spark/) documentation, we can see that the connector is available in the Maven Central Repository.\n",
    "\n",
    "Note that for the spark JDBC connection to work, the following --packages org.postgresql:postgresql:42.5.1 was added to the spark stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+\n",
      "| symbol|            volume|               mid|                 ts|\n",
      "+-------+------------------+------------------+-------------------+\n",
      "|BTC-USD|2.1604038145086886|           5947.66|2023-03-01 00:00:00|\n",
      "|BTC-USD|3.4010091992904536|            5237.6|2023-03-01 00:01:00|\n",
      "|BTC-USD| 3.097252125417988|            6417.6|2023-03-01 00:02:00|\n",
      "|BTC-USD| 3.321120621981665|4929.6900000000005|2023-03-01 00:03:00|\n",
      "|BTC-USD|2.8235243777240364|           6584.03|2023-03-01 00:04:00|\n",
      "|BTC-USD| 4.632750296707132|           5453.74|2023-03-01 00:05:00|\n",
      "|BTC-USD|3.8039631314824702|           5122.54|2023-03-01 00:06:00|\n",
      "|BTC-USD|3.2126240899145113|           7673.62|2023-03-01 00:07:00|\n",
      "|BTC-USD|1.8925783094879787|           3867.31|2023-03-01 00:08:00|\n",
      "|BTC-USD|3.2591621183734603|           4817.47|2023-03-01 00:09:00|\n",
      "|BTC-USD|2.2492996767206943|           4622.86|2023-03-01 00:10:00|\n",
      "|BTC-USD|1.4936611049063955|           5240.25|2023-03-01 00:11:00|\n",
      "|BTC-USD| 2.132276215770374|           5527.95|2023-03-01 00:12:00|\n",
      "|BTC-USD|3.4260042583867385|            6320.1|2023-03-01 00:13:00|\n",
      "|BTC-USD| 2.474077971845269|           5552.14|2023-03-01 00:14:00|\n",
      "|BTC-USD|2.4314330424408905|           4531.76|2023-03-01 00:15:00|\n",
      "|BTC-USD|2.8231962237785626|           5034.06|2023-03-01 00:16:00|\n",
      "|BTC-USD|1.2874572848745154|           4048.53|2023-03-01 00:17:00|\n",
      "|BTC-USD| 3.510537450397911|           4292.42|2023-03-01 00:18:00|\n",
      "|BTC-USD|3.6657802800017634|           4241.38|2023-03-01 00:19:00|\n",
      "+-------+------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load 1-minute aggregated trade data into the dataframe\n",
    "df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", \"jdbc:postgresql://host.docker.internal:8812/questdb\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"user\", \"admin\")\n",
    "    .option(\"password\", \"quest\")\n",
    "    .option(\n",
    "        \"dbtable\",\n",
    "        \"(SELECT symbol, sum(amount) as volume, \"\n",
    "        \"round((max(price)+min(price))/2, 2) as mid, \"\n",
    "        \"timestamp as ts \"\n",
    "        \"FROM trades WHERE symbol = 'BTC-USD' \"\n",
    "        \"SAMPLE BY 1m ALIGN to CALENDAR) AS mid_prices\",\n",
    "    )\n",
    "    .option(\"partitionColumn\", \"ts\")\n",
    "    .option(\"numPartitions\", \"3\")\n",
    "    .option(\"lowerBound\", \"2023-03-01T00:00:00.000000Z\")\n",
    "    .option(\"upperBound\", \"2023-03-04T00:00:00.000000Z\")\n",
    "    .load()\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg, stddev, when\n",
    "\n",
    "# extract new features, clean data\n",
    "window_10 = Window.partitionBy(df.symbol).rowsBetween(-10, Window.currentRow)\n",
    "df = df.withColumn(\"ma10\", avg(df.mid).over(window_10))\n",
    "df = df.withColumn(\"std\", stddev(df.mid).over(window_10))\n",
    "df = df.withColumn(\"std\", when(df.std.isNull(), 0.0).otherwise(df.std))\n",
    "\n",
    "# save the data as 'trades_enriched', overwrite if already exists\n",
    "(\n",
    "    df.write.format(\"jdbc\")\n",
    "    .option(\"url\", \"jdbc:postgresql://host.docker.internal:8812/questdb\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"user\", \"admin\")\n",
    "    .option(\"password\", \"quest\")\n",
    "    .option(\"dbtable\", \"trades_enriched\")\n",
    "    .option(\"truncate\", True)\n",
    "    .option(\n",
    "        \"createTableColumnTypes\", \"volume DOUBLE, mid DOUBLE, ma10 DOUBLE, std DOUBLE\"\n",
    "    )\n",
    "    .save(mode=\"overwrite\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+-----------------+------------------+\n",
      "| symbol|            volume|               mid|                 ts|             ma10|               std|\n",
      "+-------+------------------+------------------+-------------------+-----------------+------------------+\n",
      "|BTC-USD|2.1604038145086886|           5947.66|2023-03-01 00:00:00|          5947.66|               0.0|\n",
      "|BTC-USD|3.4010091992904536|            5237.6|2023-03-01 00:01:00|          5592.63|502.08824104931955|\n",
      "|BTC-USD| 3.097252125417988|            6417.6|2023-03-01 00:02:00|          5867.62| 594.0579106450818|\n",
      "|BTC-USD| 3.321120621981665|4929.6900000000005|2023-03-01 00:03:00|5633.137500000001| 674.6836582367075|\n",
      "|BTC-USD|2.8235243777240364|           6584.03|2023-03-01 00:04:00|5823.316000000001| 722.6602509685998|\n",
      "|BTC-USD| 4.632750296707132|           5453.74|2023-03-01 00:05:00|          5761.72|  663.742927615805|\n",
      "|BTC-USD|3.8039631314824702|           5122.54|2023-03-01 00:06:00|5670.408571428571| 652.2985005968909|\n",
      "|BTC-USD|3.2126240899145113|           7673.62|2023-03-01 00:07:00|          5920.81| 930.7607508607446|\n",
      "|BTC-USD|1.8925783094879787|           3867.31|2023-03-01 00:08:00|5692.643333333333|1107.5045726429303|\n",
      "|BTC-USD|3.2591621183734603|           4817.47|2023-03-01 00:09:00|         5605.126| 1080.219450669374|\n",
      "|BTC-USD|2.2492996767206943|           4622.86|2023-03-01 00:10:00|5515.829090909091|1066.7239442091334|\n",
      "|BTC-USD|1.4936611049063955|           5240.25|2023-03-01 00:11:00|5451.519090909091| 1059.385297976657|\n",
      "|BTC-USD| 2.132276215770374|           5527.95|2023-03-01 00:12:00|5477.914545454545|1057.1370999956785|\n",
      "|BTC-USD|3.4260042583867385|            6320.1|2023-03-01 00:13:00|5469.050909090909| 1048.846598111035|\n",
      "|BTC-USD| 2.474077971845269|           5552.14|2023-03-01 00:14:00|5525.637272727272|1033.5164869714552|\n",
      "|BTC-USD|2.4314330424408905|           4531.76|2023-03-01 00:15:00|5339.067272727272|1008.2791350919734|\n",
      "|BTC-USD|2.8231962237785626|           5034.06|2023-03-01 00:16:00|5300.914545454545|1011.4413382926728|\n",
      "|BTC-USD|1.2874572848745154|           4048.53|2023-03-01 00:17:00|5203.277272727273|1079.9037907155516|\n",
      "|BTC-USD| 3.510537450397911|           4292.42|2023-03-01 00:18:00|4895.895454545454| 731.4144071231251|\n",
      "|BTC-USD|3.6657802800017634|           4241.38|2023-03-01 00:19:00|4929.901818181817| 686.1014525537485|\n",
      "+-------+------------------+------------------+-------------------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load 1-minute aggregated trade data into the dataframe\n",
    "df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", \"jdbc:postgresql://host.docker.internal:8812/questdb\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"user\", \"admin\")\n",
    "    .option(\"password\", \"quest\")\n",
    "    .option(\"query\", \"SELECT * FROM trades_enriched\")\n",
    "    .load()\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Streaming - QuestDB\n",
    "The following code will create a streaming dataframe from the rate source, and write the data to QuestDB.\n",
    "\n",
    "JDBC connections aren't supported by writestream API, so we'll use the foreachBatch method to write the data to QuestDB.\n",
    "\n",
    "To avoid concurrent write issues and lock contention, we'll repartition dataframe to 1 partition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "# Create a streaming DataFrame with rate source\n",
    "streamingDF = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", \"10000\").load()\n",
    "\n",
    "# Perform transformations on the streaming data\n",
    "transformedDF = streamingDF.selectExpr(\"value AS id\", \"timestamp AS event_time\")\n",
    "TABLE_NAME = \"spark_rate\"\n",
    "SPARK_WAREHOUSE_BASE_CHECKPOINT = (\n",
    "    f\"/opt/bitnami/spark/spark-warehouse/checkpoint/{TABLE_NAME}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the transformed stream to QuestDB using the JDBC format\n",
    "# def write_to_questdb(batch_df, batch_id):\n",
    "def write_to_questdb(batch_df, batch_id):\n",
    "    _ = (\n",
    "        batch_df\n",
    "        .repartition(1)\n",
    "        .write.format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:postgresql://host.docker.internal:8812/questdb\")\n",
    "        .option(\"driver\", \"org.postgresql.Driver\")\n",
    "        .option(\"user\", \"admin\")\n",
    "        .option(\"password\", \"quest\")\n",
    "        .option(\"dbtable\", TABLE_NAME)\n",
    "        .option(\"truncate\", True)\n",
    "        .save(mode=\"append\")\n",
    "    )\n",
    "\n",
    "\n",
    "query = (\n",
    "    transformedDF.writeStream.trigger(processingTime=\"1 seconds\")\n",
    "    .foreachBatch(write_to_questdb)\n",
    "    .option(\"checkpointLocation\", SPARK_WAREHOUSE_BASE_CHECKPOINT)\n",
    "    .start()\n",
    ")\n",
    "import time\n",
    "\n",
    "# Sleep for 10 seconds\n",
    "time.sleep(30)\n",
    "\n",
    "# Stop the streaming query\n",
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello-load-testing-tCkx6OFd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
